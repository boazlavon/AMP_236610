{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "wsd_model.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boazlavon/AMP_236610/blob/master/wsd_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XK8v8Ytswjr"
      },
      "source": [
        "## Studets details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3ilVVOOswj0"
      },
      "source": [
        "Student1\n",
        "* Name:\n",
        "* ID:\n",
        "* Username:\n",
        "\n",
        "Student2\n",
        "* Name:\n",
        "* ID:\n",
        "* Username:\n",
        "\n",
        "Student3\n",
        "* Name:\n",
        "* ID:\n",
        "* Username:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ0C6w9hswj0"
      },
      "source": [
        "### General tip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebYWU5dkswj1"
      },
      "source": [
        "While debugging you might want to use:\n",
        "```python\n",
        "import importlib\n",
        "importlib.reload(model)\n",
        "```\n",
        "\n",
        "to reload the model module without repeating unnecessary cells."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vowRMrcSswj1"
      },
      "source": [
        "### Import relevant packages - you might need to pip install some "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn96NYNhswj2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/gdrive/MyDrive/NLP/hw1/attention_exercise_tau')\n",
        "print(os.listdir('/content/gdrive/MyDrive/NLP/hw1/attention_exercise_tau'))\n",
        "\n",
        "import torch\n",
        "import data_loader\n",
        "from traineval import train, evaluate\n",
        "import model as model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"deviced used is {device}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tLqIx0oswj2"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31pOqomfswj3"
      },
      "source": [
        "seed = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydoGDt5nswj3"
      },
      "source": [
        "## Loading the Data\n",
        "\n",
        "The following line of code invokes data_loader and will automatically download and extract the dataset if needed.\n",
        "It instantiates the following variables;\n",
        "* tokens_vocab - the sentence words vocabulary\n",
        "* y_vocab - the labels (senses) vocabulary\n",
        "* datasets - a dictionary with train,dev, and test WSDDataset instances.\n",
        "\n",
        "Use the optional sentence_count kwarg to limit the number of sentences loaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1k8uISsswj4"
      },
      "source": [
        "train_dataset, tokens_vocab, y_vocab = data_loader.load_train_dataset()\n",
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aelj0waGswj4"
      },
      "source": [
        "dev_dataset = data_loader.load_dev_dataset(tokens_vocab, y_vocab)\n",
        "dev_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7nUT0rFswj4"
      },
      "source": [
        "## Part 1: Query-Based Attention\n",
        "\n",
        "Implement the relevant parts in model.py module. You might to check out this blog post about [gather method](https://medium.com/analytics-vidhya/understanding-indexing-with-pytorch-gather-33717a84ebc4)\n",
        "\n",
        "Load the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHoToudvswj5"
      },
      "source": [
        "dropout = 0.25\n",
        "D = 300\n",
        "lr = 8e-5\n",
        "batch_size=100\n",
        "num_epochs=5\n",
        "set_seed(seed)\n",
        "\n",
        "m = model.WSDModel(\n",
        "    tokens_vocab.size(), \n",
        "    y_vocab.size(), \n",
        "    D=D, \n",
        "    dropout_prob=dropout\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "\n",
        "losses, train_acc, val_acc = train(\n",
        "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSmewMOiswj5"
      },
      "source": [
        "Train the model - you shoud see the loss decreasing and validation acc increasing from epoch to epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpjzsRMBswj6"
      },
      "source": [
        "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
        "#assert round(val_acc[-1], 3) >= 0.514, \"The last validation accuracy should be at least 0.514. Please check your implementation before you continue\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgnUYq0Zswj6"
      },
      "source": [
        "Plot the loss and training/validation accuracy. You should be getting ~54% validation accuracy after 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hn1Tx5xswj6"
      },
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
        "\n",
        "axs[0].plot(losses, '-', label='Train Loss');\n",
        "axs[0].legend()\n",
        "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
        "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iHpeKzHswj7"
      },
      "source": [
        "Use the attention vizualization to get a feel of what the model is attending to.\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "The query token is highlighted in green, and the model's attention with a pink-blue gradient.\n",
        "In addition, the loss is given a red gradient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXoZOLM0swj7"
      },
      "source": [
        "from traineval import higlight_samples\n",
        "\n",
        "higlight_samples(m, dev_dataset, sample_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ra0NA8eswj7"
      },
      "source": [
        "## Part 2: Padding\n",
        "\n",
        "Implement the padding mask in the attention function in model.py.\n",
        "\n",
        "Load the model and retrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdSKJadoswj8"
      },
      "source": [
        "set_seed(seed)\n",
        "\n",
        "m = model.WSDModel(\n",
        "    tokens_vocab.size(), \n",
        "    y_vocab.size(), \n",
        "    D=D, \n",
        "    dropout_prob=dropout,\n",
        "    use_padding=True\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "\n",
        "losses, train_acc, val_acc = train(\n",
        "    m, optimizer, train_dataset, dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfFZQOtnswj8"
      },
      "source": [
        "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
        "#assert round(val_acc[-1], 3) >= 0.527, \"The last validation accuracy should be at least 0.527. Please check your implementation before you continue\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oOTrfPHswj8"
      },
      "source": [
        "Plot the loss and training/validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrJvubRiswj9"
      },
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
        "\n",
        "axs[0].plot(losses, '-', label='Train Loss');\n",
        "axs[0].legend()\n",
        "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
        "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSs-LMIhswj9"
      },
      "source": [
        "higlight_samples(m, dev_dataset, sample_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEFUXf2cswj9"
      },
      "source": [
        "Examine additional examples, using the API and pandas as demonstrated below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63jgr-yjswj-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from traineval import evaluate_verbose, highlight\n",
        "\n",
        "pd.set_option('max_columns', 100)\n",
        "\n",
        "eval_df, attention_df = evaluate_verbose(m, dev_dataset, iter_lim=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndmd8HKCswj-"
      },
      "source": [
        "Visualization of 5 incorrectly classified examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQsZkOeNswj-"
      },
      "source": [
        "idxs = np.where(eval_df['y_true'] != eval_df['y_pred'])\n",
        "idxs = list(idxs[0][:5])\n",
        "highlight(eval_df, attention_df, idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omUUt7xLswj_"
      },
      "source": [
        "Visualization of examples with the query word \"left\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jQogRUdswj_"
      },
      "source": [
        "idxs = np.where(eval_df['query_token'] == 'left')\n",
        "highlight(eval_df, attention_df, idxs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW_vPE0zswj_"
      },
      "source": [
        "## Part 3: Self-Attention\n",
        "\n",
        "The method below converts the query-based instances in WSDDataset to sentence-level instances in WSDSentencesDataset for self-attention.\n",
        "\n",
        "Notice how the number of samples now equals number of sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWdm7u6sswkA"
      },
      "source": [
        "sa_train_dataset = data_loader.WSDSentencesDataset.from_word_dataset(train_dataset)\n",
        "sa_train_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLP4X0XgswkA"
      },
      "source": [
        "sa_dev_dataset = data_loader.WSDSentencesDataset.from_word_dataset(dev_dataset)\n",
        "sa_dev_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9Pw2lLWswkA"
      },
      "source": [
        "Implement self-attention in the model.\n",
        "\n",
        "Load the model and retrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p2-FrU4swkB"
      },
      "source": [
        "lr=2e-4\n",
        "dropout = 0.2\n",
        "D=300\n",
        "batch_size=20\n",
        "num_epochs=5\n",
        "set_seed(seed)\n",
        "\n",
        "m = model.WSDModel(\n",
        "    tokens_vocab.size(), \n",
        "    y_vocab.size(), \n",
        "    D=D, \n",
        "    dropout_prob=dropout,\n",
        "    use_padding=True\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "\n",
        "losses, train_acc, val_acc = train(\n",
        "    m, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1OEYD0swkB"
      },
      "source": [
        "Plot the loss and training/validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0MDE0v1swkB"
      },
      "source": [
        "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
        "#assert val_acc[-1] >= 0.543, \"The last validation accuracy should be at least 0.543. Please check your implementation before you continue\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950apnCDswkB"
      },
      "source": [
        "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
        "\n",
        "axs[0].plot(losses, '-', label='Train Loss');\n",
        "axs[0].legend()\n",
        "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
        "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJY-Xz7bswkC"
      },
      "source": [
        "## Part 4: Positional embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEkIH5VWswkC"
      },
      "source": [
        "We do not provide \"you code here\" comments for this part as you should be familiar with the code by now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEwQAafswkD"
      },
      "source": [
        "lr=2e-4\n",
        "dropout = 0.2\n",
        "D=300\n",
        "batch_size=20\n",
        "num_epochs=5\n",
        "set_seed(seed)\n",
        "\n",
        "m = model.WSDModel(\n",
        "    tokens_vocab.size(), \n",
        "    y_vocab.size(), \n",
        "    D=D, \n",
        "    dropout_prob=dropout,\n",
        "    use_padding=True,\n",
        "    use_relative_pos=True\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "losses, train_acc, val_acc = train(\n",
        "    m, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)\n",
        "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
        "\n",
        "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
        "\n",
        "axs[0].plot(losses, '-', label='Train Loss');\n",
        "axs[0].legend()\n",
        "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
        "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfRGt1ETswkD"
      },
      "source": [
        "## Part 5: Causal Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpuuVL7dswkD"
      },
      "source": [
        "We do not provide \"you code here\" comments for this part as you should be familiar with the code by now"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDZO4gaHswkD"
      },
      "source": [
        "lr=2e-4\n",
        "dropout = 0.2\n",
        "D=300\n",
        "batch_size=20\n",
        "num_epochs=5\n",
        "set_seed(seed)\n",
        "\n",
        "m = model.WSDModel(\n",
        "    tokens_vocab.size(), \n",
        "    y_vocab.size(), \n",
        "    D=D, \n",
        "    dropout_prob=dropout,\n",
        "    use_padding=True,\n",
        "    use_relative_pos=False,\n",
        "    use_subsequent_mask=True\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "losses, train_acc, val_acc = train(\n",
        "    m, optimizer, sa_train_dataset, sa_dev_dataset, num_epochs=num_epochs, batch_size=batch_size)\n",
        "print(f\"Validation accuracy: {val_acc[-1]:.3f}, Training accuracy:{train_acc[-1]:.3f}\")\n",
        "\n",
        "fig, axs = plt.subplots(nrows=2, figsize=(15, 6))\n",
        "\n",
        "axs[0].plot(losses, '-', label='Train Loss');\n",
        "axs[0].legend()\n",
        "axs[1].plot(train_acc, '-o', label='Train Acc');\n",
        "axs[1].plot(val_acc, '-o', label='Val Acc');\n",
        "axs[1].legend()\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3rud7bxswkE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}